{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP2ZvjXozmKfuN4VCDZa5Ij",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshitPanday/Call-Quality-Analyze/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1️⃣ Install Required Libraries\n",
        "!pip install -q yt-dlp\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q textblob\n",
        "!pip install -q pydub\n",
        "!pip install -q noisereduce\n",
        "!apt install -y ffmpeg\n",
        "\n",
        "print(\"All libraries installed successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JdndsXT5atE",
        "outputId": "ab53638b-7fb2-4fcd-cc6f-d49c8534afa3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "All libraries installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2️⃣ Download Audio from YouTube using yt-dlp\n",
        "!yt-dlp -x --audio-format wav -o \"call_audio.%(ext)s\" https://www.youtube.com/watch?v=4ostqJD3Psc\n",
        "print(\"Audio downloaded as call_audio.wav\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj7eu7PP5drL",
        "outputId": "f59f8ad0-be19-4f7f-d712-1af008cc2445"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=4ostqJD3Psc\n",
            "[youtube] 4ostqJD3Psc: Downloading webpage\n",
            "[youtube] 4ostqJD3Psc: Downloading tv simply player API JSON\n",
            "[youtube] 4ostqJD3Psc: Downloading tv client config\n",
            "[youtube] 4ostqJD3Psc: Downloading tv player API JSON\n",
            "[info] 4ostqJD3Psc: Downloading 1 format(s): 251\n",
            "[download] call_audio.wav has already been downloaded\n",
            "[ExtractAudio] Destination: call_audio.wav\n",
            "Deleting original file call_audio.orig.wav (pass -k to keep)\n",
            "Audio downloaded as call_audio.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3️⃣ Optional: Preprocess Audio (Noise Reduction)\n",
        "import librosa\n",
        "import noisereduce as nr\n",
        "import soundfile as sf\n",
        "\n",
        "y, sr = librosa.load(\"call_audio.wav\", sr=None)\n",
        "reduced_noise = nr.reduce_noise(y=y, sr=sr)\n",
        "sf.write(\"call_audio_denoised.wav\", reduced_noise, sr)\n",
        "print(\"Noise reduction completed, file saved as call_audio_denoised.wav\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-Go5UM95gYF",
        "outputId": "0f7c5dbb-a18f-4b80-8ed7-8579858d5b74"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noise reduction completed, file saved as call_audio_denoised.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4️⃣ Speech-to-Text using Whisper\n",
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"call_audio_denoised.wav\")\n",
        "transcript = result['text']\n",
        "print(\"Transcription:\\n\", transcript)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62EhSOh_5jwS",
        "outputId": "b4eda8ed-0aaf-48ff-b1ac-f33918c056a8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 51.8MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription:\n",
            "  Thank you for calling Nissan. My name is Lauren. Can I have your name? How many is John Smith? Thank you John. How can I help you? I was just calling about to see how much you would cost to update the map in my car. I'd have to help you with that today. Did you receive a mail from us? I did. Do you need the customer number? Yes please. Okay. It's 152430. Thank you and the year making model of your vehicle. Yeah I have a 2009 Nissan Altima. Oh nice car. Yeah thank you. We really enjoy it. Okay I think I've got your profile here. Can I have to verify your address and phone number please? Yes. It's 1255 North Research Way that's an ORM Utah 84097. And my phone number is A-01-431-1000. Thanks John. I located your information. The newest person we have available for your vehicle is version 7.7 which was released in March 2012. The price of the new map is $99.00. Push the tax. Let's go ahead and set up the order for you. Well, in the waitress a second I'm not really sure if I can afford it right now. Alright, well here are a few routes to consider purchasing today. It looks as though you have updated your vehicle for three years. So that would be the equivalent of getting three years worth of updates for the price of what? Oh okay. In addition, special offers like the current promotion don't come around too often. I would definitely recommend taking advantage of the extra $50 off before it is fired. Yeah, it does sound pretty good. If I set this order up for you now it will ship out today and for $50 last. Do you have your credit card candy in? I can place this order for you now. Yeah, let's go ahead and use a visa. My number?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5️⃣ Estimate Talk-Time Ratio (Approx using Whisper segments)\n",
        "# Whisper outputs timestamps for segments, we can approximate talk-time\n",
        "\n",
        "segments = result.get('segments', [])\n",
        "speaker0_duration = sum([seg['end'] - seg['start'] for seg in segments[::2]])  # approximate alternating speakers\n",
        "speaker1_duration = sum([seg['end'] - seg['start'] for seg in segments[1::2]])\n",
        "\n",
        "total_duration = sum([seg['end'] - seg['start'] for seg in segments])\n",
        "if total_duration == 0:\n",
        "    total_duration = sum([seg['end'] - seg['start'] for seg in segments]) + 1  # fallback\n",
        "\n",
        "print(f\"Approx Talk-time Ratio:\")\n",
        "print(f\"Speaker 0: {speaker0_duration/total_duration*100:.2f}%\")\n",
        "print(f\"Speaker 1: {speaker1_duration/total_duration*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWyFhsPh5l8D",
        "outputId": "03b1b087-f6c0-44d4-c357-2d7cb6de4b06"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approx Talk-time Ratio:\n",
            "Speaker 0: 61.98%\n",
            "Speaker 1: 38.02%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6️⃣ Count Questions\n",
        "questions = [s for s in transcript.split('.') if s.strip().endswith('?')]\n",
        "num_questions = len(questions)\n",
        "print(f\"Number of questions asked: {num_questions}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v7r5CFL5ocR",
        "outputId": "94d8f4bc-e04b-4a7a-8e24-045b82852102"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of questions asked: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7️⃣ Longest Monologue (Approx using longest segment)\n",
        "longest_monologue = max([seg['end'] - seg['start'] for seg in segments], default=0)\n",
        "print(f\"Longest monologue duration: {longest_monologue:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGtA_GDW5qYo",
        "outputId": "37a66afe-f103-427b-87c0-1bf924692266"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longest monologue duration: 9.36 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8️⃣ Sentiment Analysis\n",
        "from textblob import TextBlob\n",
        "\n",
        "blob = TextBlob(transcript)\n",
        "sentiment_score = blob.sentiment.polarity\n",
        "\n",
        "if sentiment_score > 0:\n",
        "    sentiment_label = \"Positive\"\n",
        "elif sentiment_score < 0:\n",
        "    sentiment_label = \"Negative\"\n",
        "else:\n",
        "    sentiment_label = \"Neutral\"\n",
        "\n",
        "print(f\"Call Sentiment: {sentiment_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw5xkegZ5sE7",
        "outputId": "aeb5e80c-749b-4dcf-d6cd-431699d1aada"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Call Sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9️⃣ Actionable Insight\n",
        "if sentiment_label == \"Negative\":\n",
        "    insight = \"Improve call tone and engagement.\"\n",
        "elif num_questions < 5:\n",
        "    insight = \"Ask more questions to engage the customer.\"\n",
        "else:\n",
        "    insight = \"Call is well-balanced and engaging.\"\n",
        "\n",
        "print(f\"Actionable Insight: {insight}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMvDgSM85uLh",
        "outputId": "53d0f37c-ef83-4d4b-ab74-ea3206a149c8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actionable Insight: Ask more questions to engage the customer.\n"
          ]
        }
      ]
    }
  ]
}